{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ylabT8SkPtI"
   },
   "source": [
    "# Code Exclusive to Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15586,
     "status": "ok",
     "timestamp": 1736985867257,
     "user": {
      "displayName": "Charles Yoo",
      "userId": "10848566476897055966"
     },
     "user_tz": 300
    },
    "id": "5HpOC3G9kFIJ",
    "outputId": "22183a11-6040-460b-f5d6-4bad701eab74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "  # Mount Google Drive to notebook\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  import sys\n",
    "  sys.path.append('/content/gdrive/My Drive/Colab Notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COaKf2MVkOdl"
   },
   "outputs": [],
   "source": [
    "if 'COLAB_GPU' in os.environ:\n",
    "  # Set configuration file to access AWS\n",
    "  os.environ['AWS_CONFIG_FILE']=\"/content/gdrive/My Drive/cred-stockdata.txt\"\n",
    "  # Set environment variables\n",
    "  os.environ[\"bucket\"] = \"026090555438-stockdata\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsO7xm4pkSVo"
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-gsxNliHkS9V"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import datetime\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0jHHz0zzoNz"
   },
   "source": [
    "# AccessS3 Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-FW5YbOzoGW"
   },
   "outputs": [],
   "source": [
    "# Class for accessing s3\n",
    "class AccessS3:\n",
    "  def __init__(self):\n",
    "    # Setup s3 client\n",
    "    session = boto3.Session()\n",
    "    self.s3 = session.client('s3')\n",
    "    self.paginator = self.s3.get_paginator('list_objects_v2')\n",
    "\n",
    "  # Get an object\n",
    "  # Arg: bucket [str] **bucket name**,\n",
    "  #      key [str] **object key**,\n",
    "  # Returns: [s3 obj]\n",
    "  def getObj(self, bucket, key):\n",
    "    return self.s3.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "  # Delete an object\n",
    "  # Arg: bucket [str] **bucket name**,\n",
    "  #      key [str] **object key**\n",
    "  def deleteObj(self, bucket, key):\n",
    "    self.s3.delete_object(Bucket=bucket, Key=key)\n",
    "    print(\"Deleted object at {}\".format(key))\n",
    "    return 0\n",
    "\n",
    "  # Save an object\n",
    "  # Arg: data [obj] **data to be saved**\n",
    "  #      bucket [str] **bucket name**,\n",
    "  #      key [str] **object key**\n",
    "  def saveObj(self, data, bucket, key):\n",
    "    self.s3.put_object(\n",
    "      Body=data,\n",
    "      Bucket=bucket,\n",
    "      Key=key\n",
    "    )\n",
    "    print(\"Saved object at {}\".format(key))\n",
    "    return 0\n",
    "\n",
    "  # Return objects contained in a key\n",
    "  # Arg: bucket [str] **bucket name**,\n",
    "  #      key [str] **object key**\n",
    "  #      sort [str] default None **sort entries by upload date \"newFirst\" newest to oldest \"newLast\" oldest to newest**\n",
    "  # Returns: objs [list of s3 objs] **objects in key**\n",
    "  def scanObjs(self, bucket, key, sort=None):\n",
    "    objs = []\n",
    "    # Get all objects in bucket and key pair\n",
    "    pages = self.paginator.paginate(Bucket=bucket, Prefix=key)\n",
    "    # if you would like to sort the objects by upload dates,\n",
    "    if sort:\n",
    "      for page in pages:\n",
    "        for content in page['Contents']:\n",
    "          # Only add objects that do not end in \"/\" (folder keys end in \"/\")\n",
    "          if not content['Key'].endswith(\"/\"):\n",
    "            objs.append(content)\n",
    "      # Sort by last modified date\n",
    "      lastModified = lambda obj: int(obj['LastModified'].strftime('%s'))\n",
    "      if sort==\"newFirst\":\n",
    "        sortedObjs =  [obj['Key'] for obj in sorted(objs, key=lastModified, reverse=True)]\n",
    "      elif sort==\"newLast\":\n",
    "        sortedObjs =  [obj['Key'] for obj in sorted(objs, key=lastModified)]\n",
    "      return sortedObjs\n",
    "    # otherwise,\n",
    "    else:\n",
    "      # Convert iterator to list\n",
    "      for page in pages:\n",
    "        for content in page['Contents']:\n",
    "          # Only add object keys that do not end in \"/\" (folder keys end in \"/\")\n",
    "          if not content['Key'].endswith(\"/\"):\n",
    "            objs.append(content['Key'])\n",
    "      return objs\n",
    "\n",
    "  # Look up a specific object\n",
    "  # Arg: bucket [str] **bucket name**\n",
    "  #      key [str] **lookup key**\n",
    "  #      subKey [str] **substring of key to look for**\n",
    "  # Returns: matchObjs [list of s3 objs] **object key if it exists**\n",
    "  def lookupObj(self, bucket, key, subKey):\n",
    "    matchObjs = []\n",
    "    # Return objects contained in a key\n",
    "    objs = self.scanObjs(bucket, key)\n",
    "    # Add object keys that contain the lookup substring\n",
    "    for obj in objs:\n",
    "      if subKey in obj:\n",
    "        matchObjs.append(obj)\n",
    "    return matchObjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQe3xdf2RbxL"
   },
   "source": [
    "# Get publication dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ro4BSa4XRbpa"
   },
   "outputs": [],
   "source": [
    "# Get publication dates of files\n",
    "# Arg: bucket [str] **bucket name**,\n",
    "#      keys [list of str] **list of keys that require dates**\n",
    "#      s3Helper [AccessS3 Instance]\n",
    "# Returns: dates [list of str] **list of dates for keys**\n",
    "def getDates(bucket, keys, s3Helper):\n",
    "  dates = []\n",
    "  for key in keys:\n",
    "    date = (json.loads(s3Helper.getObj(bucket, key)['Body'].read().decode()))\n",
    "    dates.append(date[\"date\"])\n",
    "  return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bytx1QtDQqdY"
   },
   "source": [
    "# Convert publication dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zd-p_-DfQqVK"
   },
   "outputs": [],
   "source": [
    "# Convert publication dates of files\n",
    "# Arg: unstrDates [list of str] **unstructed dates**\n",
    "# Returns: [list of str] **list of structured dates**\n",
    "def convertDates(unstrDates):\n",
    "  dateFormat = \"%a, %d %b %Y %H:%M:%S %Z\"\n",
    "  return [datetime.datetime.strptime(unstrDate, dateFormat) for unstrDate in unstrDates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4-4UChfjaWR"
   },
   "source": [
    "# Lookup a key in a list of keys (not accessing s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6H2oeTajaj8"
   },
   "outputs": [],
   "source": [
    "# Look up a key in a list of keys\n",
    "# Arg: keys [list of str] **list of keys to look in**\n",
    "#      lookupKey [str] **key to lookup**\n",
    "# Returns: matchKeys [list of str] **list of matching keys**\n",
    "def lookupKeys(keys, lookupKey):\n",
    "  matchKeys = [key for key in keys if lookupKey in key]\n",
    "  return matchKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cW_cpYHruVF"
   },
   "source": [
    "# Delete Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QMkV7kshka1n"
   },
   "outputs": [],
   "source": [
    "# Find duplicates and delete old ones\n",
    "# Arg: bucket [str] **bucket name**\n",
    "def deleteDup(bucket):\n",
    "  # Set up AccessS3 class and deletion counter\n",
    "  s3Helper = AccessS3()\n",
    "  count = 0\n",
    "  # Get all object keys and entry ids in the bucket\n",
    "  objs = s3Helper.scanObjs(bucket, \"metadata\")\n",
    "  ids = [obj.rsplit('/', 1)[-1].split('.')[0] for obj in objs]\n",
    "  # Count occurences of each id in the bucket\n",
    "  occurences = Counter(ids)\n",
    "  for id, occurence in occurences.items():\n",
    "    # if the id occurs more than once,\n",
    "    if occurence > 1:\n",
    "      # Get all keys that match the id\n",
    "      matchMetaKeys = lookupKeys(objs, id)\n",
    "      matchTextKeys = [\"textdata/\"+key.split(\"/\",1)[1] for key in matchMetaKeys]\n",
    "      # Get the dates for each occurence and convert them to comparable datetime objects\n",
    "      metaDates = getDates(bucket, matchMetaKeys, s3Helper)\n",
    "      matchDates = convertDates(metaDates)\n",
    "      newDate = max(matchDates)\n",
    "      for metakey, textkey, date in zip(matchMetaKeys, matchTextKeys, matchDates):\n",
    "        # Delete occurences that are not the most recent one\n",
    "        if not date==newDate:\n",
    "          #print(\"Deleted {}\".format(metakey))\n",
    "          #print(\"Deleted {}\".format(textkey))\n",
    "          s3Helper.deleteObj(bucket, metakey)\n",
    "          s3Helper.deleteObj(bucket, textkey)\n",
    "          count += 1\n",
    "  print(\"{} have been deleted\".format(count))\n",
    "  return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4x4pWqAUkdvR"
   },
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEGKgnxkke_W"
   },
   "outputs": [],
   "source": [
    "def main(event, context):\n",
    "  bucket = os.environ[\"bucket\"]\n",
    "  deleteDup(bucket)\n",
    "  return {\n",
    "      'statusCode': 200\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zv99FoGVkkGQ"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 57269,
     "status": "ok",
     "timestamp": 1736985954757,
     "user": {
      "displayName": "Charles Yoo",
      "userId": "10848566476897055966"
     },
     "user_tz": 300
    },
    "id": "qzFl2VBBkmZI",
    "outputId": "c8a09950-3c95-482c-d404-75dafc3f63af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 have been deleted\n",
      "{'statusCode': 200}\n"
     ]
    }
   ],
   "source": [
    "if 'COLAB_GPU' in os.environ:\n",
    "  result = main(None, None)\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycLGmWzlUTIH"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(None, None)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOli+xlylfJur38mVEqD6Qc",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
